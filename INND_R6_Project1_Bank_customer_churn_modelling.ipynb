{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INND_R6_Project1.Bank customer churn modelling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSLJ7kvIY1fk"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.activations import relu\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u8tsvtqZfuA",
        "outputId": "64192905-6ff2-4d29-f236-0705916127c0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_888SuJbkjB"
      },
      "source": [
        "\n",
        "# Read in Bank Customer Chrun data\n",
        "\n",
        "Customer_df = pd.read_csv('/content/drive/My Drive/Churn_Modelling.csv')\n"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njGwh4enriEk"
      },
      "source": [
        "\n",
        "# Dropping the unique fields\n",
        "Customer_df.drop([\"RowNumber\",\"Surname\",\"CustomerId\"],axis=1,inplace=True)\n"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP2Turejzb8o"
      },
      "source": [
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# creating instance of labelencoder\n",
        "labelencoder = LabelEncoder()\n",
        "#enc = OneHotEncoder(handle_unknown='ignore')"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSt3B9qJ1mna"
      },
      "source": [
        "\n",
        "Customer_df['Gender'] = labelencoder.fit_transform(Customer_df['Gender'])\n",
        "\n",
        "\n",
        "#X_train = enc.fit(X_train)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "rz04GlKer-lY",
        "outputId": "6fff96e8-07fe-4337-d452-6fd48cf00b72"
      },
      "source": [
        "Customer_df.head()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore Geography  Gender  ...  IsActiveMember  EstimatedSalary  Exited\n",
              "0          619    France       0  ...               1        101348.88       1\n",
              "1          608     Spain       0  ...               1        112542.58       0\n",
              "2          502    France       0  ...               0        113931.57       1\n",
              "3          699    France       0  ...               0         93826.63       0\n",
              "4          850     Spain       0  ...               1         79084.10       0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSuYf9LHsQoF"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore')"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-K2B4o3sC0d"
      },
      "source": [
        "# passing bridge-types-cat column (label encoded values of bridge_types)\n",
        "enc_df = pd.DataFrame(enc.fit_transform(Customer_df[['Geography']]).toarray())\n",
        "# merge with main df bridge_df on key values\n",
        "Customer_df = Customer_df.join(enc_df)\n"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "EdfBM-QztKnb",
        "outputId": "d296c460-9364-4a6e-f86f-8ac55c4482e4"
      },
      "source": [
        "Customer_df.head()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore Geography  Gender  Age  ...  Exited    0    1    2\n",
              "0          619    France       0   42  ...       1  1.0  0.0  0.0\n",
              "1          608     Spain       0   41  ...       0  0.0  0.0  1.0\n",
              "2          502    France       0   42  ...       1  1.0  0.0  0.0\n",
              "3          699    France       0   39  ...       0  1.0  0.0  0.0\n",
              "4          850     Spain       0   43  ...       0  0.0  0.0  1.0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyPyYSGUtkpB"
      },
      "source": [
        "\n",
        "# dropping Geography field which has been converted int ocategorical\n",
        "Customer_df.drop([\"Geography\"],axis=1,inplace=True)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz4bP8K71twb"
      },
      "source": [
        "\n",
        "\n",
        "# Import `train_test_split` from `sklearn.model_selection`\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting teh data into x and y\n",
        "Y = Customer_df['Exited']\n",
        "X=Customer_df.iloc[:,0:11]\n",
        "\n",
        "\n",
        "\n",
        "# Split the data up in train and test sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=42)\n"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1e1bBC8x_JW"
      },
      "source": [
        "# Standarization\n",
        "\n",
        "\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#scaler = StandardScaler()\n",
        "\n",
        "#X_train = scaler.fit_transform(X_train)\n",
        "#X_test = scaler.transform(X_test)\n"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1LfqXfjOd7L",
        "outputId": "7a559920-37e3-4c11-c0cc-30a3c445b1a7"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7000, 11), (3000, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCI3vl7UzxgX"
      },
      "source": [
        "Normalization of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "126QecJUyHcD"
      },
      "source": [
        "#Normalization\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# normalize the data attributes\n",
        "X_train = preprocessing.normalize(X_train)\n",
        "X_test = preprocessing.normalize(X_test)\n"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzx6y27tnPD6",
        "outputId": "a9892905-4364-4b57-d787-a63b4f30c22d"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7000, 11), (3000, 11))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H9olx1z2xr2"
      },
      "source": [
        "# Convert data to NumPy array\n",
        "\n",
        "# importing library\n",
        "#import numpy \n",
        "\n",
        "\n",
        "# converting list to array\n",
        "\n",
        "#X_train = numpy.asarray(X_train)\n",
        "#X_test = numpy.asarray(X_test)\n",
        "\n",
        "#Y_train = numpy.asarray(y_train)\n",
        "#Y_test = numpy.asarray(y_test)\n"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM2tZ7Emtf6k"
      },
      "source": [
        "\n",
        "# Initialize the constructor\n",
        "model = Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())   \n",
        "\n",
        "# Add an input layer \n",
        "model.add(Dense(11, activation ='relu'))\n",
        "# Add more hidden layer \n",
        "model.add(Dense(9, activation='relu'))\n",
        "model.add(Dense(7, activation='relu'))\n",
        "model.add(Dense(5, activation='relu'))\n",
        "model.add(Dense(3, activation='relu'))\n",
        "# Add an output layer \n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf0a5Ut6uKe3"
      },
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'] )"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vg95THolUhPH",
        "outputId": "31ba34a9-8c05-43e7-8bde-f484b8fe6b2f"
      },
      "source": [
        "# Compile model\n",
        "epochs = 80\n",
        "lrate = 0.01\n",
        "\n",
        "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, batch_size=25 )\n",
        "loss,test_accuracy  = model.evaluate(X_test, Y_test, verbose=False)\n",
        "print(\"model training accuracy :\" , history.history['accuracy'])\n",
        "print(\"model validation accuracy : \", history.history['val_accuracy'])\n",
        "print(\"model test accuracy : \", test_accuracy)\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy / loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['trng_acc', 'val_acc' , 'trng_loss' , 'val_loss'], loc='best')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "280/280 [==============================] - 1s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 2/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 3/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 4/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 5/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 6/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 7/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 8/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 9/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 10/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 11/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 12/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 13/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 14/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 15/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 16/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 17/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 18/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 19/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 20/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 21/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 22/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 23/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 24/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 25/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 26/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 27/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 28/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 29/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 30/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 31/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 32/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 33/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 34/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 35/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 36/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 37/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 38/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 39/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 40/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 41/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 42/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 43/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 44/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 45/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 46/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 47/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 48/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 49/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 50/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 51/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 52/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 53/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 54/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 55/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 56/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 57/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 58/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 59/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 60/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 61/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 62/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 63/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 64/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 65/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 66/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 67/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 68/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 69/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 70/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 71/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 72/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 73/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 74/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 75/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 76/80\n",
            "280/280 [==============================] - 0s 1ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 77/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 78/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 79/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "Epoch 80/80\n",
            "280/280 [==============================] - 0s 2ms/step - loss: 2.4744e-08 - accuracy: 0.7924 - val_loss: 2.3206e-08 - val_accuracy: 0.8053\n",
            "model training accuracy : [0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006, 0.7924285531044006]\n",
            "model validation accuracy :  [0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414, 0.8053333163261414]\n",
            "model test accuracy :  0.8053333163261414\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmFpgTV_50LE"
      },
      "source": [
        "pred=model.predict(X_test)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hodQ_QFZDMhZ",
        "outputId": "fd621115-f352-4b61-b4e2-9c630984ffe7"
      },
      "source": [
        "pred"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49729303],\n",
              "       [0.4949623 ],\n",
              "       [0.4951054 ],\n",
              "       ...,\n",
              "       [0.4937214 ],\n",
              "       [0.49507636],\n",
              "       [0.497216  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLgt5T60NgDZ"
      },
      "source": [
        "Converting Prob Values to binary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP2AhLm5NnVg"
      },
      "source": [
        "ypred=[int(p>=0.5) for p in pred]"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV4O82onoCVh"
      },
      "source": [
        "Classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5bs9vCLN17Y",
        "outputId": "0f01ad73-301c-4a1f-e062-2080f3844ba3"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(Y_test, ypred))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.99      0.89      2416\n",
            "           1       0.10      0.00      0.01       584\n",
            "\n",
            "    accuracy                           0.80      3000\n",
            "   macro avg       0.45      0.50      0.45      3000\n",
            "weighted avg       0.67      0.80      0.72      3000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjGrWuYtQFAc"
      },
      "source": [
        "Confusion Matrx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8vZvAD6PmAJ",
        "outputId": "475a2c11-ef0e-4e53-cfdd-1cd8e2b5c7d3"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(Y_test,ypred))"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2397   19]\n",
            " [ 582    2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY7ZYP0cPrri",
        "outputId": "8288f6b2-3f7b-4364-e7d6-e8854f54ff9f"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Test Accuracy: \",accuracy_score(Y_test,ypred))"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.7996666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}